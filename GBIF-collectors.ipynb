{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71560433",
   "metadata": {},
   "source": [
    "## BiCIKL-Hackathon Topic 9: Hidden Women in Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b646a6d",
   "metadata": {},
   "source": [
    "____\n",
    "### Workplan\n",
    "____\n",
    "\n",
    "1. Get a list of botanists off GBIF that are affiliated with records from around 1850/1880 (test subset)\n",
    "2. Try to pick out full names, both to make resolution easier and to identify likely not-men - whats the % of each in the data?\n",
    "3. Try to resolve names against Bionomia - what fails and why\n",
    "4. For names that aren't found in Binomia, try and resolve against wikidata\n",
    "5. Use any wikidata QIDs resulting from 3. and 4. to get gender label\n",
    "6. For names that aren't found in either source: try a few broad-brush approaches to identifying which ones might be women (could look for titles eg 'Ms Miss Mrs' or use gender-spotting API etc)\n",
    "7. For recs that might be women, run against GBIF occ ID again to get an idea of years of activity (slightly nonsensical in the test dataset, admittedly), major taxonomic groups of study, institutions of deposition? Useful output would be a set of unk women with enough hooks about their activities to encourage human research\n",
    "8. Could also run names against BHL OCR text search to get a list of possible references together to augment 7.  \n",
    "\n",
    "[Topic overview](https://github.com/pensoft/BiCIKL/tree/main/Topic%209%20Hidden%20women%20in%20science)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee294d",
   "metadata": {},
   "source": [
    "___\n",
    "### Prep\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adcbdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "687ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year_range = 1870\n",
    "end_year_range = 1900\n",
    "gbif_taxon_id = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a100e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve a unique list of values in GBIF occurrence dwc.recordedBy fields for a given date range and taxon  \n",
    "\n",
    ":param start_year: start year of query date range (YYYY)\n",
    ":param end_year: end year of query date range (YYYY)\n",
    ":param taxon_key: GBIF taxon key\n",
    ":return: Set of names (unique strings)\n",
    "\"\"\"\n",
    "def get_gbif_recordedBy(start_year, end_year, taxon_key):\n",
    "    # Get the value of recordedBy for each record, where it exists\n",
    "    collectors = set()\n",
    "    \n",
    "    for offset in itertools.count(step=300):\n",
    "        r = requests.get(f\"https://api.gbif.org/v1/occurrence/search?year={start_year},{end_year}&basisOfRecord=PRESERVED_SPECIMEN&taxon_key={36}&limit=300&offset={offset}\").json()\n",
    "        \n",
    "        # Comment this out if you don't want to keep an eye on the progress of the queries\n",
    "        print(f\"offset: {offset}\")\n",
    "        \n",
    "        # Get the info we're interested in\n",
    "        # Could beef this up in the future to grab recordedBy ID, inst/dataset ID, taxa of interest, years of activity?\n",
    "        for d in r['results']:\n",
    "            if 'recordedBy' in d:\n",
    "                recordedBy = d['recordedBy']\n",
    "                # These delimiters seem to usually indicate > 1 name, so split and add back in\n",
    "                collectors.update(split_multiple_names(recordedBy, '&|\\|| and |;'))  \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if r['endOfRecords']:\n",
    "            break\n",
    "\n",
    "    return collectors\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Check for binomia matches\n",
    "\n",
    "\"\"\"\n",
    "def search_binomia_people_auto(names, start_year, end_year, cutoff_score=40):\n",
    "    autocomplete_base_url =  'https://api.bionomia.net/user.json?q=' # Useful to get confidence scores of match\n",
    "    details_base_url = 'https://api.bionomia.net/users/search?q=' # Holds more metadata, but no score\n",
    "    \n",
    "    matches = []\n",
    "    unmatches = []\n",
    "    \n",
    "    # url encode each name string and get result + score from autocomplete_base_url\n",
    "    for name in names:\n",
    "        response = requests.get(f\"{autocomplete_base_url}{urllib.parse.quote_plus(name)}&limit=1\")\n",
    "        response.raise_for_status()\n",
    "                           \n",
    "        # Un-matching queries return an empty list\n",
    "        if len(response.text) == 2:\n",
    "            print(f\"No matches found for {name}\")\n",
    "            unmatches.append(name)\n",
    "        else:\n",
    "            # stash top result dict with original query/name string\n",
    "            # keys: ['id', 'score', 'orcid', 'wikidata', 'fullname', 'fullname_reverse', 'thumbnail', 'lifespan', 'description'] \n",
    "            json_response = response.json()\n",
    "            top_match = json_response[0]\n",
    "            if top_match['score'] < cutoff_score:\n",
    "            #    print(f\"No matches above score {cutoff_score} found for {name}... Best score is {top_match['score']}: {top_match['fullname']}\")\n",
    "                unmatches.append(name)\n",
    "            else:\n",
    "            #    print(f\"Match found for {name}: {top_match['fullname']}. Score: {top_match['score']}\")\n",
    "                matches.append({'original_name': json_response[0]})\n",
    "\n",
    "                            \n",
    "                            \n",
    "    # Next steps for matches (might be better in its own function?)\n",
    "    # if score is below confidence level/no match against query once year is included, tag w reason for fail \n",
    "    # + store in a separate structure for info. \n",
    "\n",
    "    return matches, unmatches\n",
    "\n",
    "\"\"\"\n",
    "Break up strings that include common list delimiter characters \n",
    "\n",
    ":param input_names: iterable of names that might be a stringified list\n",
    ":param delimiters: Pipe delimited, single-string list of split-on characters. e.g., '&|\\|| and |;'\n",
    ":return: Input list with additional items resulting from split appended\n",
    "\"\"\"\n",
    "def split_multiple_names(input_names, delimiters):\n",
    "    \n",
    "    return [s.strip() for s in re.split(delimiters, input_names)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Identify strings which are more likely to contain a full given name vs. those that probably don't. \n",
    "Filters out single-word strings, leading or trailing single-character initials, unless the string also includes\n",
    "a title in (Mrs, Miss)\n",
    "\n",
    ":param input_names: iterable of names\n",
    ":return: List of full names, list of thinner/harder-to-resolve names\n",
    "\"\"\"\n",
    "def get_rid_of_gunk(input_names):\n",
    "    good_names = []\n",
    "    initials = []\n",
    "    \n",
    "    for p_name in input_names: # there's probably a better way of combining all these regex eh sarah\n",
    "        front_match = re.search('^[a-zA-Z]{3}', p_name)\n",
    "        tail_match = re.search('[a-zA-Z]{3}$', p_name)\n",
    "        multi_words = re.search('\\s', p_name)\n",
    "        \n",
    "        # Only keep if there's a miss/mrs title, or if it doesn't start or end with an initial\n",
    "        if (front_match and tail_match and multi_words) or 'Mrs' in p_name or 'Miss' in p_name:\n",
    "            good_names.append(p_name)\n",
    "        else:\n",
    "            initials.append(p_name)\n",
    "        \n",
    "    return good_names, initials\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a616cd",
   "metadata": {},
   "source": [
    "____\n",
    "### 1. Get GBIF botanist sample\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "caa90c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset: 0\n",
      "offset: 300\n",
      "offset: 600\n",
      "offset: 900\n",
      "offset: 1200\n",
      "offset: 1500\n",
      "offset: 1800\n",
      "offset: 2100\n",
      "offset: 2400\n",
      "offset: 2700\n",
      "offset: 3000\n",
      "offset: 3300\n",
      "offset: 3600\n",
      "offset: 3900\n",
      "offset: 4200\n",
      "offset: 4500\n",
      "offset: 4800\n",
      "offset: 5100\n",
      "offset: 5400\n",
      "offset: 5700\n",
      "offset: 6000\n",
      "offset: 6300\n",
      "offset: 6600\n",
      "offset: 6900\n",
      "offset: 7200\n",
      "offset: 7500\n",
      "offset: 7800\n",
      "offset: 8100\n",
      "offset: 8400\n",
      "offset: 8700\n",
      "offset: 9000\n",
      "offset: 9300\n",
      "offset: 9600\n",
      "offset: 9900\n",
      "offset: 10200\n",
      "offset: 10500\n",
      "offset: 10800\n",
      "offset: 11100\n",
      "offset: 11400\n",
      "offset: 11700\n",
      "offset: 12000\n",
      "offset: 12300\n",
      "offset: 12600\n",
      "offset: 12900\n",
      "offset: 13200\n",
      "offset: 13500\n",
      "offset: 13800\n",
      "offset: 14100\n",
      "offset: 14400\n",
      "offset: 14700\n",
      "offset: 15000\n",
      "offset: 15300\n",
      "offset: 15600\n",
      "offset: 15900\n",
      "offset: 16200\n",
      "offset: 16500\n",
      "offset: 16800\n",
      "offset: 17100\n",
      "offset: 17400\n",
      "offset: 17700\n",
      "offset: 18000\n",
      "offset: 18300\n",
      "offset: 18600\n",
      "offset: 18900\n",
      "offset: 19200\n",
      "offset: 19500\n",
      "offset: 19800\n",
      "offset: 20100\n",
      "offset: 20400\n",
      "offset: 20700\n",
      "offset: 21000\n",
      "offset: 21300\n",
      "offset: 21600\n",
      "offset: 21900\n",
      "offset: 22200\n",
      "offset: 22500\n",
      "offset: 22800\n",
      "offset: 23100\n",
      "offset: 23400\n",
      "offset: 23700\n",
      "offset: 24000\n",
      "offset: 24300\n",
      "offset: 24600\n",
      "offset: 24900\n"
     ]
    }
   ],
   "source": [
    "# Set daterange of interest and taxon-id (easily grabbable from occ search GUI url)\n",
    "gbif_collectors = get_gbif_recordedBy(start_year_range, end_year_range, gbif_taxon_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2254cb3",
   "metadata": {},
   "source": [
    "Other things that might be interesting:\n",
    "* How much is recordedByID being used? What kind of IDs are in there?\n",
    "* Distribution/frequency of each name variant within result set\n",
    "* Are names consistent within datasets/institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188743d8",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 2. ID easier-to-resolve names\n",
    "_______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef7b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_names, initials = get_rid_of_gunk(gbif_collectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ceb0cde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abeleven THAJ',\n",
       " 'Alan Dersin',\n",
       " 'Alb. Nilsson',\n",
       " 'Albatross Expedition',\n",
       " 'Albert Grunow',\n",
       " 'Albert R. Sweetster',\n",
       " \"Albertis (d'), Enrico Alberto\",\n",
       " 'Alberto Löfgren',\n",
       " 'Alfred Rehder',\n",
       " 'Allen Hiram Curtiss']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_names.sort()\n",
    "\n",
    "# Peek at the top 10 names\n",
    "good_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b57362ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full name count: 355, initials count: 1699'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Full name count: {len(good_names)}, initials count: {len(initials)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8a015",
   "metadata": {},
   "source": [
    "_To-do : add summary chart of count of fuller names vs less full?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54562e18",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 3. Try to resolve against Binomia\n",
    "_______\n",
    "\n",
    "Using two endpoints: autocomplete widget and JSON-LD search for people endpoint  \n",
    "Docs: https://bionomia.net/developers\n",
    "\n",
    "##### Notes and other interesting stuff\n",
    "\n",
    "1. Does the order of words in a name matter? aka, any difference from `forename, surname` pattern vs `surname, forename`?  \n",
    "    * Doesn't look like it. e.g., the two calls below bring back the same match with an identical score (43.65668):   \n",
    "        `https://api.bionomia.net/user.json?q=Nilsson+Alb.&limit=1`  \n",
    "        `https://api.bionomia.net/user.json?q=Alb.+Nilsson&limit=1`  \n",
    "        \n",
    "            \n",
    "2. Does having a title/indicator of marital status make any difference to number of matches/scores?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be6f8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches found for Davy, J.Burtt\n",
      "No matches found for Exp. Vanadis\n",
      "No matches found for Kroon JSA\n",
      "No matches found for Museo Nacional\n"
     ]
    }
   ],
   "source": [
    "# pass in list of names and date range\n",
    "matches, unmatches = search_binomia_people_auto(good_names, start_year=start_year_range, end_year=end_year_range)\n",
    "\n",
    "# See if there's much diff between confidence/match level for full vs initial-based names (manually spoof names for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437452e",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "#### Scratch\n",
    "_______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5b41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do: Test against binomia and wikidata resolution endpoint...\n",
    "# If we don't need to shuffle the names around to get a match, don't bother with this bit.\n",
    "names_with_commas = [(x, len(x.split())) for x in good_names if ',' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bed9825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holden Isaac\n",
      "Setchell, W. A., C. P. Nott\n",
      "George William Traill\n",
      "Julio Augusto Henriques\n",
      "Hugo Lojka\n",
      "Enrico Alberto Albertis (d')\n",
      "Lamy de la Chapelle, Pierre Marie Édouard\n",
      "Cora E. Pease, Eloise Butler\n",
      "Frank Shipley Collins\n",
      "Mrs. E. Snyder\n",
      "Setchell, W. A., I. Holden\n",
      "Setchell, W. A., R. A. Lawson\n",
      "William Nylander\n",
      "Isaac Newton\n",
      "W.A. Mrs Weymouth\n",
      "Ernst Bernhard Almquist\n",
      "Pease, C. E., E. Butler\n",
      "Butler Eloise\n",
      "Mrs Gale\n",
      "Robert Collector: Wollny\n",
      "Otto Nordstedt\n",
      "Mrs. G.A. Hall\n",
      "J.Burtt Davy\n",
      "Isaac Holden\n",
      "Miss Ryan\n",
      "Paul Collector: Kuckuck\n",
      "Henry Albert Green\n",
      "R.A. Mrs Bastow\n",
      "Setchell, W. A., A. A. Lawson\n",
      "Mrs. Bainbridge\n",
      "Setchell, W. A., R. E. Gibbs\n",
      "Albert Des Méloizes\n",
      "Miss Gale\n",
      "Mrs A. Beal\n",
      "Stephen Johnson\n"
     ]
    }
   ],
   "source": [
    "## from this batch, looks like strings with > 4 whitespace chars are more than one name?\n",
    "joined_back_up = []\n",
    "\n",
    "for cn in names_with_commas:\n",
    "    if cn[1] < 5:\n",
    "        # split and reverse it\n",
    "        reversed_name = cn[0].split(', ')\n",
    "        reversed_name.reverse()\n",
    "        back_together = ' '.join(reversed_name) # this doesn't work all the time but literally nothing does sooo\n",
    "        print(back_together)\n",
    "    else:\n",
    "        print(cn[0])\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif-api",
   "language": "python",
   "name": "gbif-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
