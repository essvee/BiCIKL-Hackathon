{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71560433",
   "metadata": {},
   "source": [
    "## BiCIKL-Hackathon Topic 9: Hidden Women in Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b646a6d",
   "metadata": {},
   "source": [
    "____\n",
    "### Workplan\n",
    "____\n",
    "\n",
    "1. ~Get a list of botanists off GBIF that are affiliated with records from around a test subset of records (taxon, eveny year)~\n",
    "2. ~Try to pick out full names, both to make resolution easier and to identify likely not-men - whats the frequency of each in the data?~\n",
    "3. ~Try to resolve names against Bionomia - what fails and why~\n",
    "4. For names that aren't found in Binomia, try and resolve against wikidata\n",
    "5. Use any wikidata QIDs resulting from 3. and 4. to get gender label\n",
    "6. For names that aren't found in either source: try a few broad-brush approaches to identifying which ones might be women (could look for titles eg 'Ms Miss Mrs' or use gender-spotting API etc)\n",
    "7. For recs that might be women, run against GBIF occ ID again to get an idea of years of activity (slightly nonsensical in the test dataset, admittedly), major taxonomic groups of study, institutions of deposition? Useful output would be a set of unk women with enough hooks about their activities to encourage human research\n",
    "8. Could also run names against BHL OCR text search to get a list of possible references together to augment 7.  \n",
    "\n",
    "[Topic overview](https://github.com/pensoft/BiCIKL/tree/main/Topic%209%20Hidden%20women%20in%20science)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee294d",
   "metadata": {},
   "source": [
    "___\n",
    "### Imports and params\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcbdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import urllib.parse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year_range = 1870\n",
    "end_year_range = 1870\n",
    "gbif_taxon_id = 7819616\n",
    "confidence = 51"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b80e4d",
   "metadata": {},
   "source": [
    "___\n",
    "### Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a7f5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve a unique list of values in GBIF occurrence dwc.recordedBy fields for a given date range and taxon  \n",
    "\n",
    ":param start_year: start year of query date range (YYYY)\n",
    ":param end_year: end year of query date range (YYYY)\n",
    ":param taxon_key: GBIF taxon key\n",
    ":return: Set of names (unique strings)\n",
    "\"\"\"\n",
    "def get_gbif_recordedBy(start_year, end_year, taxon_key):\n",
    "    # Get the value of recordedBy for each record, where it exists\n",
    "    collectors = set()\n",
    "    \n",
    "    for offset in itertools.count(step=300):\n",
    "        r = requests.get(f\"\"\"https://api.gbif.org/v1/occurrence/search?year={start_year},{end_year}\n",
    "        &basisOfRecord=PRESERVED_SPECIMEN&taxon_key={gbif_taxon_id}&limit=300&offset={offset}\"\"\").json()\n",
    "        \n",
    "        # Comment this out if you don't want to keep an eye on the progress of the queries\n",
    "        # print(f\"offset: {offset}\")\n",
    "        \n",
    "        # Get the info we're interested in\n",
    "        # Could beef this up in the future to grab recordedBy ID, inst/dataset ID, taxa of interest, years of activity?\n",
    "        for d in r['results']:\n",
    "            if 'recordedBy' in d:\n",
    "                recordedBy = d['recordedBy']\n",
    "                # These delimiters seem to usually indicate > 1 name, so split and add back in\n",
    "                collectors.update(split_multiple_names(recordedBy, '&|\\|| and |;'))  \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if r['endOfRecords']:\n",
    "            break\n",
    "\n",
    "    return collectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25cddae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lil utility func to turn a single gbif species id into something human-readable\n",
    "\"\"\"\n",
    "\n",
    "def get_species_label(gbif_species_id):\n",
    "    response = requests.get(f\"https://api.gbif.org/v1/species/{gbif_species_id}\")\n",
    "    json_response = response.json()\n",
    "    name_label = json_response['scientificName']\n",
    "    \n",
    "    return name_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6d4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Identify strings which are more likely to contain a full given name vs. those that probably don't. \n",
    "Filters out single-word strings, leading or trailing single-character initials, unless the string also includes\n",
    "a title in (Mrs, Miss)\n",
    "\n",
    ":param input_names: iterable of names\n",
    ":return: List of full names, list of thinner/harder-to-resolve names\n",
    "\"\"\"\n",
    "def get_rid_of_gunk(input_names):\n",
    "    good_names = []\n",
    "    initials = []\n",
    "    \n",
    "    for p_name in input_names: # there's probably a better way of combining all these regex eh sarah\n",
    "        front_match = re.search('^[a-zA-Z]{3}', p_name)\n",
    "        tail_match = re.search('[a-zA-Z]{3}$', p_name)\n",
    "        multi_words = re.search('\\s', p_name)\n",
    "        \n",
    "        # Only keep if there's a miss/mrs title, or if it doesn't start or end with an initial\n",
    "        if (front_match and tail_match and multi_words) or 'Mrs' in p_name or 'Miss' in p_name:\n",
    "            good_names.append(p_name)\n",
    "        else:\n",
    "            initials.append(p_name)\n",
    "        \n",
    "    return good_names, initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3969ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break up strings that include common list delimiter characters \n",
    "\n",
    ":param input_names: iterable of names that might be a stringified list\n",
    ":param delimiters: Pipe delimited, single-string list of split-on characters. e.g., '&|\\|| and |;'\n",
    ":return: Input list with additional items resulting from split appended\n",
    "\"\"\"\n",
    "def split_multiple_names(input_names, delimiters):\n",
    "    \n",
    "    return [s.strip() for s in re.split(delimiters, input_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a100e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Broad-brush check for matches against Bionomia\n",
    "\n",
    "\"\"\"\n",
    "def search_bionomia_people_auto(names, cutoff_score=50):\n",
    "    autocomplete_base_url =  'https://api.bionomia.net/user.json?q=' # Useful to get confidence scores of match\n",
    "    \n",
    "    matches = []\n",
    "    unmatches = []\n",
    "    \n",
    "    # url encode each name string and get result + score from autocomplete_base_url\n",
    "    for name in names:\n",
    "        # If you want to keep an eye on the progress, uncomment \n",
    "#         print(f\"{name}...\")\n",
    "        \n",
    "        response = requests.get(f\"{autocomplete_base_url}{urllib.parse.quote_plus(name)}&limit=1\")\n",
    "        response.raise_for_status()\n",
    "                           \n",
    "        # Un-matching queries return an empty list\n",
    "        if len(response.text) == 2:\n",
    "            unmatches.append(name)\n",
    "        else:\n",
    "        # stash top result dict with original query/name string\n",
    "            json_response = response.json()\n",
    "            top_match = json_response[0]\n",
    "            if top_match['score'] < cutoff_score:\n",
    "                unmatches.append(name)\n",
    "            else:\n",
    "                matches.append({'original_name': name, 'bionomia_match': json_response[0]})\n",
    "\n",
    "    return matches, unmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47bdb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stricter check for matches against Bionomia - won't return matches if the collection data is not within the \n",
    "lifespan of the person defined in wikidata/bionomia (ex. year of birth)\n",
    "\n",
    "\"\"\"\n",
    "def search_bionomia_people_detail(names, year):\n",
    "    details_base_url = 'https://api.bionomia.net/users/search?'\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        # throttle the connection - getting connection timeout errors so maybe this will help...\n",
    "        time.sleep(1)\n",
    "        \n",
    "        query_params = {'q': name['original_name'], \n",
    "                        'date': year, \n",
    "                        'strict': 'true',\n",
    "                        'limit': 1\n",
    "                       }\n",
    "        response = requests.get(details_base_url, params=query_params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # print(response.url)\n",
    "        \n",
    "        json_response = response.json()\n",
    "        \n",
    "        # Check we've returned results - no score/confidence cutoff availabel here though\n",
    "        result_count = json_response['opensearch:totalResults']\n",
    "        \n",
    "        # unpack the first ['item'] in dataElement and handle no results scenario\n",
    "        if result_count == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # store in the original dict to help compare results from the different approachs\n",
    "            name['bionomia_detail_match'] = json_response['dataFeedElement'][0]['item']\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a616cd",
   "metadata": {},
   "source": [
    "____\n",
    "### 1. Get GBIF botanist sample\n",
    "____\n",
    "\n",
    "Get a sample of unique values from dwc.recordedBy fields in occurrence records (preserved specimens only) in GBIF to work with. The sample is defined by year of collection (set to c. 1870 because that's when we started to see more botanistas appearing, but it isn't so recent they'll still be alive) + taxonomic groups within Plantae (mostly to keep the number of records/processing speed at a sensible level) \n",
    "\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Anecdata but probably more historical women botanists around - flowers being ladylike n all that.\n",
    "* Doesn't look like GBIF do much with the name strings they harvest, so should be pretty representative of source data quality?\n",
    "* Bionomia records reference GBIF specimen occ records so there's already a link there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa90c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set daterange of interest and taxon-id (easily grabbable from occ search GUI url)\n",
    "gbif_collectors = get_gbif_recordedBy(start_year_range, end_year_range, gbif_taxon_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94a6ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique name strings\n",
      "Taxa of interest: Charophyta (preserved specimens only)\n",
      "Collection event date range: 1870-1870\n",
      "Count of unique names: 136\n"
     ]
    }
   ],
   "source": [
    "# Summary + counts\n",
    "taxa_name = get_species_label(gbif_taxon_id)\n",
    "print(\"Unique name strings\")\n",
    "print(f\"Taxa of interest: {taxa_name} (preserved specimens only)\")\n",
    "print(f\"Collection event date range: {start_year_range}-{end_year_range}\")\n",
    "print(f\"Count of unique names: {len(gbif_collectors)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720082e",
   "metadata": {},
   "source": [
    "##### Notes and other interesting stuff\n",
    "\n",
    "1. Should have retrieved `dwc.family` + `dwc.year` per record/unique collector name too. \n",
    "    * e.g.\n",
    "        `{'original_name': 'Alfreda Collectoro', \n",
    "            'taxa': [t1, t2, t3], \n",
    "            'year': [1870, 1870, 1871, 1864]}`\n",
    "    * Would have been useful later on, but would have been annoying to deal with splitting delimited names...  \n",
    "    \n",
    "\n",
    "2. Found a fair few recordedBy fields with 'Mrs/Miss' in them - just added them to the 'full names' list in the end, but could be worth returning them separately cos they're definitely women.\n",
    "\n",
    "##### Things I didn't get round to looking at\n",
    "\n",
    "1. How much is recordedByID being used? What kind of IDs are in there?\n",
    "2. Distribution/frequency of each name variant within result set\n",
    "3. Are names consistent within datasets/institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188743d8",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 2. ID easier-to-resolve names\n",
    "_______\n",
    "\n",
    "Attempt to parse out 'fullname' names from the collector list generated in previous steps. a.k.a, filter out names that are either a single word string, or which have a leading or trailing initial. \n",
    "\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Easy wins! \n",
    "* Fuller names = easier/less risky to disambiguate \n",
    "* Need a decent name string to do any filtering based on demographics. \n",
    "* Interested to see the proportion of names that fall into full/thin camp and the different patterns used within this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate name list from previous step into full names vs thin/initials\n",
    "fuller_names, initials = get_rid_of_gunk(gbif_collectors)\n",
    "fuller_names.sort()\n",
    "initials.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb0cde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuller names: ['Alexander Karl (Carl) Heinrich Braun', 'Axel Blytt', 'Axel Blytt, Arnell', 'Axel Tullberg', 'Blytt, Arnell', 'Bror Tydell', 'Carl Fredrik Otto Nordstedt', 'Carl Fredrik Otto Norstedt', 'Collector unknown', 'Conr. Indebetou']\n",
      "\n",
      "Thinner names: ['-. Porntin', '?', 'A Ley', 'A. Blytt, Arnell', 'A. Braun', 'A. C. H. Braun', 'A. G. Blytt', 'A. H. Curtiss', 'A. Tullberg', 'Al. Braun']\n"
     ]
    }
   ],
   "source": [
    "# Peek at the first 10 names in each\n",
    "print(f\"Fuller names: {fuller_names[:10]}\")\n",
    "print()\n",
    "print(f\"Thinner names: {initials[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b57362ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fuller_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21924/3888462142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Summary + counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;34mf\"Full name count: {len(fuller_names)}, thinner name count: {len(initials)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fuller_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Summary + counts\n",
    "f\"Full name count: {len(fuller_names)}, thinner name count: {len(initials)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52a9c2",
   "metadata": {},
   "source": [
    "##### Notes and other interesting stuff\n",
    "\n",
    "1. Seems to work well enough, although full names are in the minority in all the samples I've tried. \n",
    "    * Could try clustering the names back around thin names once they've been resolved/if they can be? \n",
    "    * Outputs would need a bit of manual checking, but could be something citizen science folks would like to do + be good at?  \n",
    "    \n",
    "\n",
    "2. Still a few values that are clearly > 1 name though. \n",
    "    * Already splitting on these: & ; 'and' |, but the rem look like comma delimited... \n",
    "    * Might be splittable using whitespace counts? \n",
    "    * Had a go at splitting on ',' symbols where there were 4+ whitespaces in the string, but decided not to go with it because I don't know enough about name patterns worldwide.\n",
    "\n",
    "##### Things I didn't get round to looking at\n",
    "\n",
    "1. Wonder if particular patterns of errors are characteristic to institutions? It does feel that fields like recordedBy are usable/consistent enough within institutions, so no-one fixes them up much, but sufficiently different within them that linking them is a 'mare, which might mean they're distinctive enough to be useful... \n",
    "2. Frequency of each name in terms of occurrence record count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54562e18",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 3. Try to resolve against Bionomia\n",
    "_______\n",
    "\n",
    "We're trying to match the full collector names from previous steps to profiles on Bionomia, using a couple of API endpoints: autocomplete widget and JSON-LD search for people (former give a confidence match score, latter allows additional search params to help narrow search)  \n",
    "\n",
    "Docs: https://bionomia.net/developers\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Seems a good source of names + there was an nice API for searching them - seemed rude not to.\n",
    "* Everything in Bionomia has to have either an ORCiD or all of [birth date, death date, wikidata QID] and for the date range we're looking at, ORCiDs seem unlikely. So. Everything we match in bionomia is also a match against wikidata (but not necessarily vice versa)\n",
    "* Wikidata record means a person-id we can maybe trust, yay!\n",
    "* We're trying to light up 'lost' people, so unmatching names are of interest because they aren't in bionomia, but the people were collectors... \n",
    "* ... or occurence recordedBy strings are garbled beyond matchability, which is also useful - how much do they need to be cleaned up before they match well enough? Are there other (poss. easier to clean/infer) fields that could help increase match confidence?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6f8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Karl (Carl) Heinrich Braun...\n",
      "Axel Blytt...\n",
      "Axel Blytt, Arnell...\n",
      "Axel Tullberg...\n",
      "Blytt, Arnell...\n",
      "Bror Tydell...\n",
      "Carl Fredrik Otto Nordstedt...\n",
      "Carl Fredrik Otto Norstedt...\n",
      "Collector unknown...\n",
      "Conr. Indebetou...\n",
      "Conrad Indebetou...\n",
      "Edouard Rostan...\n",
      "Flodén, Alexis...\n",
      "Frederic Stratton...\n",
      "Frederick Arnold Lees...\n",
      "Gust. Bernoulli...\n",
      "Hampus Wilhelm Arnell...\n",
      "Herb Suringar WFR...\n",
      "Herb Weber-van Bosse...\n",
      "Jair Törnblad...\n",
      "James Groves...\n",
      "Jean Armand Isidore Pancher...\n",
      "Johan Elias Strömberg...\n",
      "John Thomas Irvine Boswell Syme...\n",
      "Lars Johan Wahlstedt...\n",
      "Lundquist, Per Fredrik Alexander...\n",
      "Mag. Östman...\n",
      "Mag. Östmann...\n",
      "Nordstedt CFO...\n",
      "Nordstedt, Carl Fredrik Otto...\n",
      "Otto Nordstedt...\n",
      "Strömborg, Johan Elias...\n",
      "Tullberg, Sven Axel Teodor...\n",
      "Wahlstedt, Lars Johan...\n",
      "Wilhelm Berndes...\n",
      "William Curnow...\n",
      "see Collection Note...\n"
     ]
    }
   ],
   "source": [
    "# pass in list of names and date range\n",
    "matches, unmatches = search_bionomia_people_auto(good_names, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69b4c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a confidence cutoff of 51, 19 out of 37 full names were matched against the basic Bionomia endpoint\n"
     ]
    }
   ],
   "source": [
    "print(f\"With a confidence cutoff of {confidence}, {len(matches)} out of {len(good_names)} full names were matched against the basic Bionomia endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09149ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Karl (Carl) Heinrich Braun -> Alexander Braun (Q62855)\n",
      "Axel Blytt -> Axel Gudbrand Blytt (Q610981)\n",
      "Axel Tullberg -> Sven Axel Tullberg (Q6335227)\n",
      "Carl Fredrik Otto Nordstedt -> Carl Fredrik Otto Nordstedt (Q6015981)\n",
      "Edouard Rostan -> Edouard Rostan (Q21607448)\n",
      "Frederic Stratton -> Frederic Stratton (Q21609937)\n",
      "Frederick Arnold Lees -> Frederick Arnold Lees (Q21518563)\n",
      "Gust. Bernoulli -> Carl Gustav Bernoulli (Q121991)\n",
      "Hampus Wilhelm Arnell -> Hampus Wilhelm Arnell (Q5559534)\n",
      "Herb Weber-van Bosse -> Anna Weber-van Bosse (Q1940785)\n",
      "James Groves -> James Groves (Q21512721)\n",
      "Jean Armand Isidore Pancher -> Jean Armand Isidore Pancher (Q3170415)\n",
      "John Thomas Irvine Boswell Syme -> John Thomas Irvine Boswell Syme (Q5933649)\n",
      "Lars Johan Wahlstedt -> Lars Johan Wahlstedt (Q16650555)\n",
      "Mag. Östman -> Magnus Östman (Q21522469)\n",
      "Nordstedt CFO -> Carl Fredrik Otto Nordstedt (Q6015981)\n",
      "Otto Nordstedt -> Carl Fredrik Otto Nordstedt (Q6015981)\n",
      "Wilhelm Berndes -> Wilhelm Eugene Berndes (Q21506016)\n",
      "William Curnow -> William Curnow (Q21509664)\n"
     ]
    }
   ],
   "source": [
    "# Quick eyeball to QC results\n",
    "for match in matches:\n",
    "    print(f\"{match['original_name']} -> {match['bionomia_match']['fullname']} ({match['bionomia_match']['wikidata']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026beed",
   "metadata": {},
   "source": [
    "##### Notes and other interesting stuff\n",
    "\n",
    "1. Does the order of words in a name matter? aka, any difference from `forename, surname` pattern vs `surname, forename`?  \n",
    "    * Doesn't look like it. e.g., the two calls below bring back the same match with an identical score (43.65668):   \n",
    "        `https://api.bionomia.net/user.json?q=Nilsson+Alb.&limit=1`  \n",
    "        `https://api.bionomia.net/user.json?q=Alb.+Nilsson&limit=1`  \n",
    " \n",
    "   \n",
    "2. Hard to say from limited sample size, but the JSON-LD endpoint seemed to match less accurately than the basic one\n",
    "    * Either collection dates are off (and so fall outside lifespan of collector)\n",
    "    * Or collection dates are correct and what looks like a perfect match is someone with the same name at a different time (this would imply the true collector isn't in Bionomia yet, I suppose?)\n",
    "    * .... could be both, of course. JSON-LD endpoint doesn't give the match score so hard to QC, either way. \n",
    "    * You can pass in families collected as well, which might help, but I reckon that comes from GBIF data links anyway & if it doesn't it's probably real mucky so would need resolving first.\n",
    "    * confidence cutoff for the basic API seemed to hit a sweet spot in terms of accuracy around 51\n",
    "\n",
    "##### Things I didn't get round to looking at\n",
    "\n",
    "1. Does having a title/indicator of marital status make any difference to number of matches/scores?\n",
    "2. How good is each endpoint at resolving non-full names? Would think it's risky unless you have a bunch of other match points, and tbf the responsibility for thin names is at data creation/collection so maybe infra should design services around the assumption of decent source data. The carrot can also be the stick ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae41e34",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- run queries that found a match + year of interest against the JSON-LD bionomia endpoint \n",
    "- see if abbreviated names work against the JSON-LD endpoint, providing there's a year -- skip for now\n",
    "- ~Stash any good matches for now~ - yup, but need to write 'em out somewhere  \n",
    "- for full names what don't match: ID women and then try to run them against wikidata\n",
    "- If there is a match in wikidata: figure out the best info etc to dumpout to encourage folks to make profiles on bionomia\n",
    "- No match on wikidata or bionomia: clustering names/families of research? Look in BHL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ad3f5",
   "metadata": {},
   "source": [
    "___\n",
    "### 4. Some things that didn't work, but in an interesting way \n",
    "___\n",
    "Don't run these unless you especially want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591f5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Will using year of collection + json-ld endpoint removed/improve these? Looking for improved accuracy, not precision\n",
    "strict_matches = search_bionomia_people_detail(matches, start_year_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... okay this made it worse. Ha!\n",
    "print(f\"recordedBy value; bionomia best match (match score); bionomia + year of collection best match\")\n",
    "print(\"--------\")\n",
    "\n",
    "for i in strict_matches:\n",
    "    if 'bionomia_detail_match' in i:\n",
    "        strict_fullname = i['bionomia_detail_match']['name']\n",
    "    else:\n",
    "        strict_fullname = 'Not found'\n",
    "        \n",
    "    print(f\"{i['original_name']} -> {i['bionomia_match']['fullname']} ({i['bionomia_match']['score']}) -> {strict_fullname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accbd9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the records where the first bionomia name suggestion differed from the result returned \n",
    "# when year of collection is included... Assume either collection date or collector lifespan is wrong? \n",
    "\n",
    "print(f\"recordedBy value; bionomia best match (match score); bionomia + year of collection best match\")\n",
    "print(\"--------\")\n",
    "\n",
    "for p in strict_matches:\n",
    "    if 'bionomia_detail_match' in p:\n",
    "        if p['bionomia_match']['fullname'] != p['bionomia_detail_match']['name']:\n",
    "            print(f\"{p['original_name']}; {p['bionomia_match']['fullname']} ({p['bionomia_match']['score']}); {p['bionomia_detail_match']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12240647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif-api",
   "language": "python",
   "name": "gbif-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
