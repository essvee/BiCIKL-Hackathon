{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71560433",
   "metadata": {},
   "source": [
    "## BiCIKL-Hackathon Topic 9: Hidden Women in Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b646a6d",
   "metadata": {},
   "source": [
    "____\n",
    "### Workplan\n",
    "____\n",
    "\n",
    "1. ~Get a list of botanists off GBIF that are affiliated with records from around a test subset of records (taxon, eveny year)~\n",
    "2. ~Try to pick out full names, both to make resolution easier and to identify likely not-men - whats the frequency of each in the data?~\n",
    "3. ~Try to resolve names against Bionomia - what fails and why~\n",
    "4. ~Use any wikidata QIDs resulting from 3 to get gender label~\n",
    "\n",
    "5. For names that aren't found in either source: try a few broad-brush approaches to identifying which ones might be women (could look for titles eg 'Ms Miss Mrs' or use gender-spotting API etc)\n",
    "6. For recs that might be women, run original name against GBIF occ search of years of activity, major taxonomic groups of study, institutions of deposition? Useful output would be a set of unk women with enough hooks about their activities to encourage human research\n",
    "7. Could also run names against BHL OCR text search to get a list of possible references together to augment 7.  \n",
    "\n",
    "[Topic overview](https://github.com/pensoft/BiCIKL/tree/main/Topic%209%20Hidden%20women%20in%20science)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee294d",
   "metadata": {},
   "source": [
    "___\n",
    "### Imports and params\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcbdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import urllib.parse\n",
    "import time\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year_range = 1880\n",
    "end_year_range = 1880\n",
    "# gbif_taxon_id = 7819616\n",
    "gbif_taxon_id = 6\n",
    "confidence = 51\n",
    "wikidata_username = 'Essssveeee'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b80e4d",
   "metadata": {},
   "source": [
    "___\n",
    "### Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a7f5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve a unique list of values in GBIF occurrence dwc.recordedBy fields for a given date range and taxon  \n",
    "\n",
    ":param start_year: start year of query date range (YYYY)\n",
    ":param end_year: end year of query date range (YYYY)\n",
    ":param taxon_key: GBIF taxon key\n",
    ":return: Set of names (unique strings)\n",
    "\"\"\"\n",
    "def get_gbif_recordedBy(start_year, end_year, taxon_key):\n",
    "    # Get the value of recordedBy for each record, where it exists\n",
    "    collectors = set()\n",
    "    \n",
    "    for offset in itertools.count(step=300):\n",
    "        r = requests.get(f\"\"\"https://api.gbif.org/v1/occurrence/search?year={start_year},{end_year}\n",
    "        &basisOfRecord=PRESERVED_SPECIMEN&taxon_key={gbif_taxon_id}&limit=300&offset={offset}\"\"\").json()\n",
    "        \n",
    "        # print(f\"offset: {offset}\")\n",
    "        \n",
    "        # Get the info we're interested in\n",
    "        # Could expand get recordedBy ID, inst/dataset ID, taxa of interest, years of activity?\n",
    "        for d in r['results']:\n",
    "            if 'recordedBy' in d:\n",
    "                recordedBy = d['recordedBy']\n",
    "                # These delimiters seem to usually indicate > 1 name, so split and add back in\n",
    "                collectors.update(split_multiple_names(recordedBy, '&|\\|| and |;'))  \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if r['endOfRecords']:\n",
    "            break\n",
    "\n",
    "    return collectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806828b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility func to turn a single gbif species id into something human-readable\n",
    "\"\"\"\n",
    "\n",
    "def get_species_label(gbif_species_id):\n",
    "    response = requests.get(f\"https://api.gbif.org/v1/species/{gbif_species_id}\")\n",
    "    json_response = response.json()\n",
    "    name_label = json_response['scientificName']\n",
    "    \n",
    "    return name_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6d4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Identify strings which are more likely to contain a full given name vs. those that probably don't. \n",
    "Filters out single-word strings, leading or trailing single-character initials, unless the string also includes\n",
    "a title in (Mrs, Miss)\n",
    "\n",
    ":param input_names: iterable of names\n",
    ":return: List of full names, list of thinner/harder-to-resolve names\n",
    "\"\"\"\n",
    "def get_rid_of_gunk(input_names):\n",
    "    good_names = []\n",
    "    initials = []\n",
    "    \n",
    "    for p_name in input_names: # there's probably a better way of combining all these regex eh sarah\n",
    "        front_match = re.search('^[a-zA-Z]{3}', p_name)\n",
    "        tail_match = re.search('[a-zA-Z]{3}$', p_name)\n",
    "        multi_words = re.search('\\s', p_name)\n",
    "        \n",
    "        # Only keep if there's a miss/mrs title, or if it doesn't start or end with an initial\n",
    "        if (front_match and tail_match and multi_words) or 'Mrs' in p_name or 'Miss' in p_name:\n",
    "            good_names.append(p_name)\n",
    "        else:\n",
    "            initials.append(p_name)\n",
    "        \n",
    "    return good_names, initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3969ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break up strings that include common list delimiter characters \n",
    "\n",
    ":param input_names: iterable of names that might be a stringified list\n",
    ":param delimiters: Pipe delimited, single-string list of split-on characters. e.g., '&|\\|| and |;'\n",
    ":return: Input list with additional items resulting from split appended\n",
    "\"\"\"\n",
    "def split_multiple_names(input_names, delimiters):\n",
    "    \n",
    "    return [s.strip() for s in re.split(delimiters, input_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a100e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Broad-brush check for matches against Bionomia\n",
    "\n",
    "\"\"\"\n",
    "def search_bionomia_people_auto(names, cutoff_score=50):\n",
    "    autocomplete_base_url =  'https://api.bionomia.net/user.json?q=' # Useful to get confidence scores of match\n",
    "    \n",
    "    matches = []\n",
    "    unmatches = []\n",
    "    \n",
    "    # url encode each name string and get result + score from autocomplete_base_url\n",
    "    for name in names:\n",
    "\n",
    "        #print(f\"{name}...\")\n",
    "        \n",
    "        response = requests.get(f\"{autocomplete_base_url}{urllib.parse.quote_plus(name)}&limit=1\")\n",
    "        response.raise_for_status()\n",
    "                           \n",
    "        # Un-matching queries return an empty list\n",
    "        if len(response.text) == 2:\n",
    "            unmatches.append(name)\n",
    "        else:\n",
    "        # stash top result dict with original query/name string\n",
    "            json_response = response.json()\n",
    "            top_match = json_response[0]\n",
    "            if top_match['score'] < cutoff_score:\n",
    "                unmatches.append(name)\n",
    "            else:\n",
    "                matches.append({'original_name': name, 'bionomia_match': json_response[0]})\n",
    "\n",
    "    return matches, unmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bdb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stricter check for matches against Bionomia - won't return matches if the collection data is not within the \n",
    "lifespan of the person defined in wikidata/bionomia (ex. year of birth)\n",
    "\n",
    "\"\"\"\n",
    "def search_bionomia_people_detail(names, year):\n",
    "    details_base_url = 'https://api.bionomia.net/users/search?'\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        # throttle the connection - getting connection timeout errors so maybe this will help...\n",
    "        time.sleep(1)\n",
    "        \n",
    "        query_params = {'q': name['original_name'], \n",
    "                        'date': year, \n",
    "                        'strict': 'true',\n",
    "                        'limit': 1\n",
    "                       }\n",
    "        response = requests.get(details_base_url, params=query_params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # print(response.url)\n",
    "        \n",
    "        json_response = response.json()\n",
    "        \n",
    "        # Check we've returned results - no score/confidence cutoff availabel here though\n",
    "        result_count = json_response['opensearch:totalResults']\n",
    "        \n",
    "        # unpack the first ['item'] in dataElement and handle no results scenario\n",
    "        if result_count == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # store in the original dict to help compare results from the different approachs\n",
    "            name['bionomia_detail_match'] = json_response['dataFeedElement'][0]['item']\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b07c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_botanists(endpoint_url, query):\n",
    "\n",
    "    user_agent = f\"WDQS-example Python/{sys.version_info[0]}.{sys.version_info[1]} ({wikidata_username})\"\n",
    "    \n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a616cd",
   "metadata": {},
   "source": [
    "____\n",
    "### 1. Get GBIF botanist sample\n",
    "____\n",
    "\n",
    "Get a sample of unique values from dwc.recordedBy fields in occurrence records (preserved specimens only) in GBIF to work with. The sample is defined by year of collection (set to c. 1870 because that's when we started to see more botanistas appearing, but it isn't so recent they'll still be alive) + taxonomic groups within Plantae (mostly to keep the number of records/processing speed at a sensible level) \n",
    "\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Anecdata but probably more historical women botanists around - flowers being ladylike n all that.\n",
    "* Doesn't look like GBIF do much with the name strings they harvest, so should be pretty representative of source data quality?\n",
    "* Bionomia records reference GBIF specimen occ records so there's already a link there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa90c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set daterange of interest and taxon-id (easily grabbable from occ search GUI url)\n",
    "gbif_collectors = get_gbif_recordedBy(start_year_range, end_year_range, gbif_taxon_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06dd0b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique name strings\n",
      "Taxa of interest: Plantae (preserved specimens only)\n",
      "Collection event date range: 1880-1880\n",
      "Count of unique names: 9430\n"
     ]
    }
   ],
   "source": [
    "# Summary + counts\n",
    "taxa_name = get_species_label(gbif_taxon_id)\n",
    "print(\"Unique name strings\")\n",
    "print(f\"Taxa of interest: {taxa_name} (preserved specimens only)\")\n",
    "print(f\"Collection event date range: {start_year_range}-{end_year_range}\")\n",
    "print(f\"Count of unique names: {len(gbif_collectors)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f8cbf",
   "metadata": {},
   "source": [
    "##### Notes \n",
    "\n",
    "1. Could have retrieved `dwc.family` + `dwc.year` per record/unique collector name too. \n",
    "            {'original_name': 'Alfreda Collectoro', \n",
    "            'taxa': [t1, t2, t3],\n",
    "            'year': [1870, 1870, 1871, 1864]}  \n",
    "        \n",
    "    * Might have been useful later on, but also would have been annoying to deal with \n",
    "    \n",
    "\n",
    "2. Found a fair few recordedBy fields with 'Mrs/Miss' in them - just added them to the 'full names' list in the end, but could be worth returning them separately cos they're definitely women.\n",
    "\n",
    "##### Interesting questions\n",
    "\n",
    "1. How much is recordedByID being used? What kind of IDs are in there?\n",
    "2. Distribution/frequency of each name variant within result set\n",
    "3. Are names consistent within datasets/institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188743d8",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 2. ID easier-to-resolve names\n",
    "_______\n",
    "\n",
    "Attempt to parse out 'fullname' names from the collector list generated in previous steps. a.k.a, filter out names that are either a single word string, or which have a leading or trailing initial. \n",
    "\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Easy wins! \n",
    "* Fuller names = easier/less risky to disambiguate \n",
    "* Need a decent name string to do any filtering based on demographics. \n",
    "* Interested to see the proportion of names that fall into full/thin camp and the different patterns used within this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate name list from previous step into full names vs thin/initials\n",
    "fuller_names, initials = get_rid_of_gunk(gbif_collectors)\n",
    "fuller_names.sort()\n",
    "initials.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb0cde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuller names: ['Abbé A. Carestia', 'Abbé Post', 'Abd-Ur-Rahman Nadji', 'Abeleven THAJ', 'Abraham P. Garber', 'Abram P. Garber', 'Abrams, Le Roy', 'Adalbert Geheeb', 'Addison Brown', 'Adler, Per']\n",
      "\n",
      "Thinner names: ['', '(Dr.) C. Håkansson', '(Johann) Albert von Regel', '(Johann) Hermann Fischer-Sigwart', '(Viktor) Theodor Wartmann', '(n/a)', '(unknown)', '* BEHREND', '* CARDER', '* GIMNEZ']\n"
     ]
    }
   ],
   "source": [
    "# Peek at the first 10 names in each\n",
    "print(f\"Fuller names: {fuller_names[:10]}\")\n",
    "print()\n",
    "print(f\"Thinner names: {initials[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57362ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full name count: 1858, thinner name count: 7572'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary + counts\n",
    "f\"Full name count: {len(fuller_names)}, thinner name count: {len(initials)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50c5a2",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "\n",
    "1. Seems to work well enough, although full names are in the minority in all the samples I've tried. \n",
    "    * Could try clustering the names back around thin names once they've been resolved/if they can be? \n",
    "    * Outputs would need a bit of manual checking, but could be something citizen science folks would like to do + be good at?  \n",
    "    \n",
    "\n",
    "2. Still a few values that are clearly > 1 name though. \n",
    "    * Already splitting on these: & ; 'and' |, but the rem look like comma delimited... \n",
    "    * Might be splittable using whitespace counts? \n",
    "\n",
    "##### Interesting questions\n",
    "\n",
    "1. Are patterns of errors characteristic to institutions?\n",
    "2. Frequency of each name in terms of occurrence record count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54562e18",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 3. Try to resolve against Bionomia\n",
    "_______\n",
    "\n",
    "We're trying to match the full collector names from previous steps to profiles on Bionomia, using a couple of API endpoints: autocomplete widget and JSON-LD search for people (former give a confidence match score, latter allows additional search params to help narrow search)  \n",
    "\n",
    "Docs: https://bionomia.net/developers\n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* Seems a good source of names + there was an nice API for searching them - seemed rude not to.\n",
    "* Everything in Bionomia has to have either an ORCiD or all of [birth date, death date, wikidata QID] and for the date range we're looking at, ORCiDs seem unlikely. So. Everything we match in bionomia is also a match against wikidata (but not necessarily vice versa)\n",
    "* Wikidata record means a person-id we can maybe trust, yay!\n",
    "* We're trying to light up 'lost' people, so unmatching names are of interest because they aren't in bionomia, but the people were collectors... \n",
    "* ... or occurence recordedBy strings are garbled beyond matchability, which is also useful - how much do they need to be cleaned up before they match well enough? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in list of names and date range\n",
    "bionomia_matches, bionomia_unmatches = search_bionomia_people_auto(fuller_names, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b4c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence cutoff = 51: 614/1858 full names were matched against the basic Bionomia endpoint\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confidence cutoff = {confidence}: {len(bionomia_matches)}/{len(fuller_names)} full names were matched against the basic Bionomia endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09149ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbé A. Carestia -> Antonio Carestia (Q1111111)\n",
      "Abeleven THAJ -> Theodoor Hendrik Arnold Jacob Abeleven (Q10381986)\n",
      "Abraham P. Garber -> Abram Paschal Garber (Q21513766)\n",
      "Abram P. Garber -> Abram Paschal Garber (Q21513766)\n",
      "Adalbert Geheeb -> Adalbert Geheeb (Q69278)\n",
      "Addison Brown -> Addison Brown (Q1149854)\n",
      "Albert Commons -> A. Commons (Q21508915)\n",
      "Albert Kellogg -> Albert Kellogg (Q1368910)\n",
      "Albert Zimmeter -> Albert Zimmeter (Q86493)\n",
      "Albert von Regel -> Albert von Regel (Q354083)\n",
      "Alexander Lagus -> Anders Johan Lagus (Q11851316)\n",
      "Alexandre von Mechow -> Friedrich Wilhelm Alexander von Mechow (Q106772)\n",
      "Alfred Chabert -> Alfred Charles Chabert (Q5667427)\n",
      "Alice F. Stevens -> Alice F. McClary Stevens (Q98826765)\n",
      "Alice Heading -> Alice J. Heading (Q97940058)\n",
      "Allen H. Curtiss -> Floretta Allen Curtiss (Q76302298)\n",
      "Alois Dichtl -> Alois Dichtl (Q5670001)\n",
      "Alpheus Baker Hervey -> Alpheus Baker Hervey (Q5670534)\n",
      "Amelia F. Eby -> Amelia Flanery Eby (Q67194606)\n",
      "Anders F. Regnell -> Anders Fredrik Regnell (Q4753777)\n"
     ]
    }
   ],
   "source": [
    "# Quick look\n",
    "for match in bionomia_matches[:20]:\n",
    "    print(f\"{match['original_name']} -> {match['bionomia_match']['fullname']} ({match['bionomia_match']['wikidata']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a3da7",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "\n",
    "1. Does the order of words in a name matter? aka, any difference from `forename, surname` pattern vs `surname, forename`?  \n",
    "    * Doesn't look like it. e.g., the two calls below bring back the same match with an identical score (43.65668):   \n",
    "        `https://api.bionomia.net/user.json?q=Nilsson+Alb.&limit=1`  \n",
    "        `https://api.bionomia.net/user.json?q=Alb.+Nilsson&limit=1`  \n",
    " \n",
    "   \n",
    "2. Hard to say from limited sample size, but the JSON-LD endpoint seemed to match less accurately than the basic one\n",
    "    * Either collection dates are off (and so fall outside lifespan of collector)\n",
    "    * Or collection dates are correct and what looks like a perfect match is someone with the same name at a different time (this would imply the true collector isn't in Bionomia yet, I suppose?)\n",
    "    * .... could be both, of course. JSON-LD endpoint doesn't give the match score so hard to QC, either way. \n",
    "    * You can pass in families collected as well, which might help, but I reckon that comes from GBIF data links anyway & if it doesn't it's probably real mucky so would need resolving first.\n",
    "    * confidence cutoff for the basic API seemed to hit a sweet spot in terms of accuracy around 51\n",
    "\n",
    "##### Interesting questions\n",
    "\n",
    "1. Does having a title/indicator of marital status make any difference to number of matches/scores?\n",
    "2. How good is each endpoint at resolving non-full names? Would think it's risky unless you have a bunch of other match points, and tbf the responsibility for thin names is at data creation/collection so maybe infra should design services around the assumption of decent source data. The carrot can also be the stick ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5a677",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "### 4. Filter using wikidata\n",
    "_______\n",
    "\n",
    "Everything matched from the previous step has a wikidata identifier, and wikidata has the person's gender so could use it to tag bionomia records with gender, because that doesn't seem to be in their data.\n",
    "\n",
    "Brings back all botanists on en wikidata with a birth and death date: https://w.wiki/47QX, so if any on the bionomia matches from the last step ain't in there, they are Secret and might even be Secret Women Botanists, oooh. \n",
    "\n",
    "#### Why tho?\n",
    "\n",
    "* It'll give us a better list of 'dunno who these collectors are' and also an idea of how many might be women, based on distribution of gender in the wikidata results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f33146",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"#\n",
    "SELECT DISTINCT ?botanist ?botanistLabel ?occLabel ?birth ?death ?gender WHERE {\n",
    "  VALUES ?occ { wd:Q2374149 wd:Q2083925 } # occupations: botanist and botanical collector\n",
    "  ?botanist wdt:P106 ?occ ;               # botanist has occumpation ?occ\n",
    "            wdt:P570 ?death ;             # botanist has deathdate\n",
    "            wdt:P569 ?birth .             # botanist has birthdate\n",
    "  optional {?botanist wdt:P21 ?gender . } # botanist has gender (optional)\n",
    "  SERVICE wikibase:label {\n",
    "    bd:serviceParam wikibase:language \"en\" .\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a827806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the women botanists that are currently on wikidata\n",
    "wikidata_result = get_wikidata_botanists(endpoint_url, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd9e3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract QIDs\n",
    "def get_qid(botanist):\n",
    "    botanist_qid = botanist['botanist']['value'].rsplit('/',1)[1]\n",
    "    return botanist_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c662fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split based on value of gender tag\n",
    "wiki_botanists = wikidata_result['results']['bindings']\n",
    "\n",
    "wiki_unk = [] # gender field is null\n",
    "wiki_men = []\n",
    "wiki_women = []\n",
    "wiki_nb = [] \n",
    "\n",
    "for w_botanist in wiki_botanists:\n",
    "    if 'gender' not in w_botanist:\n",
    "        wiki_unk.append(get_qid(w_botanist))\n",
    "    elif w_botanist['gender']['value'] == 'http://www.wikidata.org/entity/Q6581072':\n",
    "        wiki_women.append(get_qid(w_botanist))\n",
    "    elif w_botanist['gender']['value'] == 'http://www.wikidata.org/entity/Q6581097':      \n",
    "        wiki_men.append(get_qid(w_botanist))\n",
    "    else:\n",
    "        wiki_nb.append(get_qid(w_botanist))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8092a9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wikidata botanist records: 19585\n",
      "\n",
      "Women botanists: 2755\n",
      "Null: 404\n",
      "Nb botanists: 0\n",
      "Men botanists: 16426\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total wikidata botanist records: {len(wiki_botanists)}\")\n",
    "print()\n",
    "print(f\"Women botanists: {len(wiki_women)}\")\n",
    "print(f\"Null: {len(wiki_unk)}\")\n",
    "print(f\"Nb botanists: {len(wiki_nb)}\")\n",
    "print(f\"Men botanists: {len(wiki_men)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac7c5a",
   "metadata": {},
   "source": [
    "___\n",
    "### 5. Known women!\n",
    "___\n",
    "\n",
    "In a specific and highly limited sense:\n",
    "- is present in gbif occurrence records\n",
    "- has a bionomia profile\n",
    "- recordedBy value is clear enough to match against bionomia\n",
    "- has gender data present in wikidata\n",
    "- ... at the very minimum, in terms of data infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3e8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "women = []\n",
    "men = []\n",
    "nb = []\n",
    "unk = []\n",
    "uhoh = []\n",
    "\n",
    "# Categorise collectors by gender\n",
    "for x in bionomia_matches:\n",
    "    \n",
    "    b_qid = x['bionomia_match']['wikidata']\n",
    "    \n",
    "    if b_qid in wiki_women:\n",
    "        women.append(b_qid)\n",
    "    elif b_qid in wiki_men:\n",
    "        men.append(b_qid)\n",
    "    elif b_qid in wiki_nb:\n",
    "        nb.append(b_qid)\n",
    "    elif b_qid in wiki_unk:\n",
    "        unk.append(b_qid)\n",
    "    else:\n",
    "        uhoh.append(b_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7ccbad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women: 22\n",
      "Men: 488\n",
      "Non-binary: 0\n",
      "Unknown: 2\n",
      "Uhoh: 102\n"
     ]
    }
   ],
   "source": [
    "print(f\"Women: {len(women)}\")\n",
    "print(f\"Men: {len(men)}\")\n",
    "print(f\"Non-binary: {len(nb)}\")\n",
    "print(f\"Unknown: {len(unk)}\")\n",
    "print(f\"Uhoh: {len(uhoh)}\") ## orcid, maybe? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbif-api",
   "language": "python",
   "name": "gbif-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
